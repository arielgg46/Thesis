\begin{resumen}
El modelado simbólico de tareas de planificación representa uno de los principales cuellos de botella para la adopción de planificadores clásicos en contextos reales. Si bien el paradigma \textit{LLM-as-Planner} ha ganado atención reciente, enfrenta serias limitaciones en verificabilidad y optimalidad. Como alternativa, esta tesis se inscribe en el enfoque \textit{LLM-as-Modeler}, en el que agentes basados en \textit{Large Language Models (LLMs)} generan automáticamente modelos \textit{PDDL (Planning Domain Definition Language)} de los problemas a partir de sus descripciones en lenguaje natural. Se propone un agente modelador modular y extensible, diseñado para mejorar la validez sintáctica, solubilidad y correctitud semántica de los modelos generados. La arquitectura combina múltiples técnicas complementarias: razonamiento estructurado en fases, generación restringida por gramática mediante \textit{Grammar-Constrained Decoding (GCD)}, \textit{feedback} automático y reflexión sobre fallos, aprendizaje experiencial con extracción y refinamiento de soluciones e \textit{insights}, y \textit{Few-Shot Prompting} enriquecido con \textit{Retrieval-Augmented Generation (RAG)}. 

La evaluación empírica se realizó sobre subconjuntos estratificados del \textit{benchmark} \textit{Planetarium}, comparando \textit{baselines} relevantes del trabajo \textit{LLM+P} y variantes del agente propuesto. Los resultados muestran mejoras significativas en todas las métricas clave, destacando la eliminación completa de errores sintácticos con \textit{GCD} mediante gramáticas especializadas y un aumento de hasta \textbf{24.3\,\%} en correctitud semántica respecto al mejor \textit{baseline} reproducido, cerrando \textbf{56.7\,\%} de su margen de mejora. La inclusión conjunta de razonamiento estructurado, extracción de objetos y \textit{GCD} permitió un desempeño de \textbf{100\,\%} en validez sintáctica, \textbf{87.1\,\%} en solubilidad y \textbf{81.4\,\%} en correctitud. Al incorporar mecanismos de reflexión y retroalimentación automática, se corrigieron errores residuales, elevando la solubilidad a \textbf{98.57\,\%} y la correctitud a \textbf{84.29\,\%}. Finalmente, la combinación sinérgica de reintentos con reflexión, recuperación de ejemplos previos e \textit{insights} construidos manualmente permitió elevar las tasas anteriores a \textbf{100\,\%} y \textbf{87.14\,\%}, respectivamente.

Este trabajo aporta una arquitectura funcional, un marco de evaluación reproducible y evidencia empírica de que los \textit{LLMs}, adecuadamente guiados y entrenados, pueden ser agentes modeladores efectivos. La propuesta abre nuevas perspectivas para el diseño de sistemas híbridos simbólico-conectivistas en planificación automática, con menor dependencia de intervención humana experta.
\end{resumen}

\begin{abstract}
Symbolic modeling of planning tasks remains one of the main bottlenecks for the practical adoption of classical planners in real-world contexts. While the \textit{LLM-as-Planner} paradigm has recently gained attention, it faces serious limitations in verifiability and optimality. As an alternative, this thesis adopts the \textit{LLM-as-Modeler} approach, in which agents based on \textit{Large Language Models (LLMs)} automatically generate \textit{PDDL (Planning Domain Definition Language)} models of planning problems from their natural language descriptions. A modular and extensible modeling agent is proposed, designed to improve the parseability, solvability, and semantic correctness of the generated models. The architecture combines multiple complementary techniques: structured multi-phase reasoning, \textit{Grammar-Constrained Decoding (GCD)}, automatic feedback and failure-driven reflection, experiential learning through solution and \textit{insight} extraction and refinement, and \textit{Few-Shot Prompting} enriched with \textit{Retrieval-Augmented Generation (RAG)}.

Empirical evaluation was conducted on stratified subsets of the \textit{Planetarium} benchmark, comparing relevant \textit{LLM+P} baselines and several variants of the proposed agent. Results show significant improvements across all key metrics, including the complete elimination of syntactic errors via \textit{GCD} with specialized grammars, and an increase of up to \textbf{24.3\,\%} in semantic correctness over the best reproduced \textit{baseline}, closing \textbf{56.7\,\%} of its performance gap. The combined inclusion of structured reasoning, object extraction, and \textit{GCD} enabled a performance of \textbf{100\,\%} parseability, \textbf{87.1\,\%} solvability, and \textbf{81.4\,\%} correctness. By incorporating mechanisms for reflection and automatic feedback, residual errors were corrected, raising solvability to \textbf{98.57\,\%} and correctness to \textbf{84.29\,\%}. Finally, the synergistic combination of retries with reflection, retrieval of prior examples, and manually constructed \textit{insights} further increased these rates to \textbf{100\,\%} and \textbf{87.14\,\%}, respectively.

This work contributes a functional architecture, a reproducible evaluation framework, and empirical evidence that properly guided and trained \textit{LLMs} can serve as effective modeling agents. The proposed approach opens new perspectives for the design of hybrid neuro-symbolic systems in automated planning, with reduced reliance on expert human intervention.
\end{abstract}