\begin{recomendations}
Esta investigación deja abiertas diversas oportunidades para profundizar y extender los resultados obtenidos. En primer lugar, sería deseable abordar las limitaciones experimentales identificadas: la evaluación no abarcó todas las combinaciones posibles de módulos del agente, ni fue exhaustiva sobre el \textit{dataset} de \textit{Planetarium}, y tampoco incluyó un análisis sistemático de la sensibilidad a los \textit{prompts}, modelos base o parámetros internos. Superar estas restricciones permitiría obtener conclusiones más robustas y generalizables sobre el impacto de cada componente del sistema.

Otra dirección prometedora consiste en ampliar el alcance del modelado más allá de los supuestos clásicos de la planificación automática, como la naturaleza determinista, estática, completamente observable y monoagente del entorno. La arquitectura propuesta podría extenderse a escenarios más realistas y desafiantes, como entornos estocásticos, parcialmente observables, multiagente, con restricciones temporales, dinámicos o con objetivos preferenciales. Además, se puede explorar la integración en entornos con entrada visual. De este modo, el sistema podría aplicarse a problemas más complejos y cercanos a los de la vida cotidiana o la industria.

Una línea prioritaria de investigación futura consiste en mejorar la calidad de la extracción automática de \textit{insights} desde la experiencia del agente. Aunque esta fase fue parcialmente implementada en esta tesis, sus resultados fueron subóptimos debido a la baja estructuración y especificidad del contenido extraído. Se recomienda explorar técnicas que impongan restricciones gramaticales o esquemáticas más estrictas sobre las salidas del modelo extractor, como \textit{GCD}. También se propone la optimización de los \textit{prompts} que recibe el modelo extractor de \textit{insights}, con énfasis en la derivación de conocimiento concreto y relevante.

Se contemplan adicionalmente otras hipótesis que la arquitectura confeccionada permite explorar:
\begin{itemize}
    \item[\textbf{H5.}] Los \textit{insights} y ejemplos de \textit{Few-Shot Prompting} específicos de un dominio pueden ser utilizados para mejorar los resultados del agente en otro dominio, como especie de \textit{Transfer learning} \parencite{zhuang2020comprehensive} sin modificación de pesos, mediante \textit{In-Context Learning}.
    \item[\textbf{H6.}] Los resultados del entrenamiento (\textit{insights} y ejemplos de soluciones correctas) del agente experiencial basado en un \textit{LLM} más complejo y costoso pueden contribuir significativamente a los resultados del mismo agente basado en un \textit{LLM} más sencillo (de varios cientos de millones menos de parámetros), abaratando costos mientras se mantiene un alto grado de rendimiento.
\end{itemize}

Se conciben algunas propuestas para su validación: se analiza una forma de transferencia de conocimiento entre dominios, donde se entrena al agente experiencial en dos dominios (\textit{Blocksworld} y \textit{Gripper}) y luego se aplica, sin reentrenamiento, en un dominio nuevo no visto durante el entrenamiento (\textit{Floor-Tile}), mediante técnicas de \textit{In-Context Learning}, conforme a la hipótesis \textbf{H5}. En todos los casos, los agentes se evalúan usando dos \textit{LLMs}, uno básico y uno avanzado, y se considera el escenario en el cual el modelo más sencillo reutiliza los \textit{insights} y ejemplos \textit{FSP} generados por el modelo más complejo, como forma de reducir el costo computacional manteniendo el rendimiento, en línea con \textbf{H6}.

También se recomienda avanzar hacia una representación más abstracta de los modelos generados, incorporando extensiones de \textit{PDDL} con cuantificadores lógicos. Esto permitiría preservar la generalidad de descripciones expresadas en lenguaje natural, evitando fijar arbitrariamente objetos específicos al traducir estados iniciales o metas. De este modo se facilitaría la generación de planes más eficientes y se reduciría la necesidad de desambiguación.

Una idea con gran potencial identificada durante el desarrollo de la tesis consiste en dotar al agente modelador de la capacidad de construir y refinar funciones o \textit{skills} que generen proposiciones \textit{PDDL} para resolver subtareas comunes. Estas funciones, codificadas por ejemplo en Python, podrían seleccionarse de forma contextual mediante \textit{RAG} sobre un repositorio en evolución, permitiendo modularidad, reutilización y aprendizaje acumulativo. Esta estrategia se inspira en trabajos como \textit{Voyager} \parencite{wang2023voyager}, y representa un paso hacia agentes con conocimientos estructurados y transferibles.

Otras líneas complementarias incluyen la incorporación de fuentes de conocimiento externo (por ejemplo, bases de sentido común o conocimiento científico), el uso de herramientas auxiliares como módulos aritméticos, la especialización funcional de los agentes mediante diferentes \textit{LLMs} por rol reentrenados con \textit{Fine-Tuning}, la integración con memorias externas estructuradas, y la exploración de métodos de combinación o ensamblado de modelos (\textit{Ensembles}). Estas estrategias pueden fortalecer la capacidad del sistema para razonar, generalizar y adaptarse a nuevos dominios, consolidando el agente modelador como una herramienta flexible y potente para tareas de planificación automática en entornos complejos.
\end{recomendations}
