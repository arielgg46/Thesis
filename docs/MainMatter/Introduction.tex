\chapter*{Introducción}\label{chapter:introduction}
\addcontentsline{toc}{chapter}{Introducción}

En las últimas décadas, los problemas de planificación han adquirido creciente relevancia tanto en el ámbito académico como industrial, al ofrecer soluciones formales para tareas que implican asignación de recursos, secuenciación de actividades o coordinación de agentes autónomos \parencite{li2024lasp, ghallab2004automated}. Desde la robótica de servicio hasta la gestión de flotas de vehículos, muchas de estas tareas pueden formularse como problemas de planificación \parencite{li2024lasp, karpas2020automated, marrella2019automated}, resueltos mediante algoritmos clásicos, como planificadores heurísticos sobre lenguajes formales como \textit{Planning Domain Definition Language (PDDL)} \parencite{aeronautiques1998pddl}. 

Pese a sus grandes beneficios, el uso de los algoritmos clásicos está limitado por la fase de modelado del problema. Sin embargo, han surgido recientemente enfoques basados en Modelos de Lenguaje de Gran Escala (\textit{Large Language Models - LLMs)}, que buscan reducir la carga del modelado simbólico o incluso reemplazar al planificador. El paradigma \textit{LLM-as-Planner} propone generar directamente secuencias de acciones desde lenguaje natural, pero presenta limitaciones importantes en factibilidad, verificabilidad y optimalidad \parencite{aghzal2025survey}. 

Como alternativa, el enfoque \textit{LLM-as-Modeler} traslada el esfuerzo al modelado automático en \textit{PDDL}, delegando la planificación a algoritmos simbólicos consolidados. Esta estrategia combina capacidades lingüísticas con garantías formales, pero aún enfrenta obstáculos relevantes: errores sintácticos, inconsistencias semánticas y fuerte dependencia de supervisión humana. Para abordar estas limitaciones, se propone utilizar estrategias complementarias como la limitación de la salida del \textit{LLM} a la sintaxis de \textit{PDDL} y su gramática correspondiente con  \textit{Grammar‑Constrained Decoding (GCD)} \parencite{geng2023grammar}, inclusión de fases previas de razonamiento estructurado y extracción de objetos, técnicas de \textit{Retrieval-Augmented Generation (RAG)} \parencite{gao2023retrieval} y aprendizaje experiencial como en el antecedente \textit{ExpeL} \parencite{zhao2024expel}, y recursos de entrenamiento y evaluación sistemática del \textit{benchmark} \textit{Planetarium} \parencite{zuo2024planetarium}. Esta tesis se inscribe en este panorama, y propone contribuir a la mejora del modelado automático con \textit{LLMs}, sin comprometer su escalabilidad ni requerir intervenciones costosas. El nombre en inglés del sistema propuesto es el acrónimo \texttt{PLAN-GRAIL}: \textit{\underline{P}lanning with \underline{L}LM-based \underline{A}gents via \underline{N}euro-symbolic modeling with \underline{G}rammar-Constrained Decoding, \underline{R}easoning and \underline{A}ctive \underline{I}n-Context \underline{L}earning}.

\section*{Motivación y Antecedentes}

Desde los años 70, la comunidad de planificación ha desarrollado lenguajes formales como \textit{STRIPS} y \textit{PDDL} \parencite{fikes1971strips, aeronautiques1998pddl}, junto con planificadores simbólicos clásicos como \textit{Fast Downward} o \textit{LAMA} \parencite{helmert2006fast, richter2011lama}, que permiten resolver tareas complejas en entornos estructurados. Sin embargo, su despliegue práctico sigue limitado por el alto costo del modelado formal: construir manualmente dominios y problemas en \textit{PDDL} requiere experticia técnica, atención a la sintaxis y comprensión profunda del dominio, lo cual restringe su adopción en contextos reales.

La aparición de los \textit{LLMs}, como \textit{GPT-3} \parencite{brown2020language}, ha motivado nuevas estrategias para aliviar esta carga. Inicialmente se exploró el paradigma \textit{LLM-as-Planner}, donde el modelo genera directamente un plan desde lenguaje natural \parencite{aghzal2025survey, wei2025plangenllms}, pero esta línea enfrenta dificultades severas en factibilidad, optimalidad y verificabilidad de los planes generados \parencite{kambhampati2024position}.

Como alternativa, surge el enfoque \textit{LLM-as-Modeler}, en el cual el \textit{LLM} traduce la descripción textual a un modelo en \textit{PDDL} del problema, delegando la búsqueda del plan a los motores clásicos \parencite{tantakoun2025llms, liu2023llm+}. Este paradigma permite aprovechar las fortalezas combinadas del procesamiento lingüístico de los \textit{LLMs} y las garantías formales de los planificadores simbólicos, pero sigue enfrentando desafíos importantes: errores sintácticos, inconsistencias semánticas y dependencia de intervención humana.

Múltiples trabajos han propuesto soluciones complementarias. Algunos exploran mecanismos intermedios o ciclos de verificación \parencite{agarwal2024tic}, mientras que otros adoptan \textit{Fine-Tuning} sobre corpus especializados \parencite{zeng2023agenttuning, zuo2024planetarium}. No obstante, estas estrategias suelen ser costosas, difíciles de escalar y dependientes de infraestructura técnica avanzada y labor humana experta, lo cual motiva la búsqueda de alternativas más ligeras y generalizables, como el \textit{In-Context Learning} \parencite{dong2022survey}.

A pesar de los avances recientes, la problemática es evidente: la generación automática de problemas \textit{PDDL} mediante \textit{LLMs} sigue enfrentando retos fundamentales, en especial en lo que respecta a la fidelidad semántica y la validez formal de los modelos producidos \parencite{zuo2024planetarium}. Aunque herramientas como \textit{Planetarium} han facilitado su evaluación sistemática, los errores persisten: el uso de predicados no declarados o tipos incorrectos, paréntesis desbalanceados, parámetros duplicados, etc., constituyen errores sintácticos del archivo \textit{PDDL} generado. Semánticamente, el uso de predicados de coexistencia contradictoria, o sin conexión con el estado inicial o los objetivos, impiden la resolución correcta del problema. Estos errores reflejan no solo dificultades con la sintaxis del lenguaje de planificación, sino también una comprensión limitada del dominio y de los requisitos lógicos implícitos en la planificación simbólica. Además, las soluciones a estos mismos problemas propuestas hasta la fecha presentan limitaciones y desventajas propias, fundamentalmente la fuerte dependencia de conocimiento experto e intervención humana laboriosa, y los altos costos computacionales.

La motivación y justificación directa de esta tesis radica en una observación concreta: aunque los algoritmos clásicos de planificación automática están disponibles y son eficaces, su uso en la práctica sigue siendo escaso debido a la complejidad del modelado. Al mismo tiempo, los \textit{LLMs} ya están integrados en diversas herramientas de software, y su potencial para ayudar en tareas estructuradas es alto si se les orienta con estrategias adecuadas, para superar las limitaciones inherentes de estos modelos y de los enfoques actuales. Esta investigación busca precisamente avanzar en esa dirección.

La existencia de ciertos trabajos anteriores inspiran directamente el enfoque que toma esta tesis, y el uso de sus estrategias y técnicas se justifica por las limitaciones identificadas que podrían aliviar. Primero, la técnica de \textit{Grammar-Constrained Decoding (GCD)} permite restringir la salida del modelo a una gramática formal predefinida, asegurando la validez sintáctica\footnote{\textit{Parseability}, término en inglés que se refiere a la correctitud sintáctica, o la propiedad de ser analizable por un \textit{parser} del lenguaje formal definido, sin errores de sintaxis.} del \textit{PDDL} generado sin modificar los pesos del modelo \parencite{geng2023grammar}. Segundo, el enfoque experiencial propuesto en \textit{ExpeL} \parencite{zhao2024expel} demuestra que los modelos pueden adquirir conocimiento estructurado de planificación a partir de ejemplos resueltos, mediante ciclos de prueba y refinamiento, en un entrenamiento previo del agente. Tercero, el \textit{benchmark Planetarium} \parencite{zuo2024planetarium} provee un \textit{corpus} masivo de pares texto-\textit{PDDL} junto con métricas automáticas de validez sintáctica, solubilidad (posibilidad de encontrar un plan válido en el dominio que llegue del estado inicial al objetivo definidos en el modelo, usualmente por un planificador clásico) y equivalencia semántica (fidelidad del modelo a la descripción en lenguaje natural del problema), lo que permite tanto el entrenamiento experiencial como la evaluación sistemática de agentes modeladores.

Estos antecedentes evidencian el potencial de combinar restricciones gramaticales, aprendizaje experiencial e infraestructura de evaluación robusta para avanzar hacia agentes modeladores con \textit{LLMs} más eficaces, generalizables y prácticos. Esta tesis se inscribe en dicha dirección.

\section*{Problema científico y Ámbito del problema}

Actualmente, los agentes basados en \textit{LLMs} que a partir de descripciones en lenguaje natural generan sus representaciones en \textit{PDDL}, con una dependencia humana reducida, presentan dificultades para asegurar que los modelos generados sean válidos sintácticamente, solubles por un planificador clásico y semánticamente correctos o fieles a la intención expresada en el texto.

El objeto de estudio de esta investigación se enmarca en la modelación automática de problemas de planificación a partir de descripciones en lenguaje natural, utilizando agentes basados en \textit{LLMs}.

El campo de acción se circunscribe al diseño e implementación de agentes basados en \textit{LLMs}, para modelación de problemas de planificación, enfocado en la generación automática de archivos \textit{PDDL} en dominios de planificación bien definidos y deterministas. Se incluye, además, la evaluación empírica de los agentes a través del \textit{benchmark Planetarium} mediante métricas de validez sintáctica, solubilidad y fidelidad semántica.

\section*{Hipótesis}
El presente trabajo plantea una serie de hipótesis acerca del impacto de distintas técnicas y estrategias que buscan mejorar los resultados, en las métricas contempladas, de agentes basados en \textit{LLMs} para modelación de tareas de planificación:

\begin{itemize}
    \item[\textbf{H1.}] La división del proceso de modelado en fases estructuradas —extracción de objetos, razonamiento, especificación del estado inicial y metas, y generación del archivo \textit{PDDL}— mejora la correctitud de los modelos generados, al permitir un razonamiento más controlado, modular y verificable.
    \item[\textbf{H2.}] La aplicación de \textit{GCD}  permite una generación más confiable del código \textit{PDDL}, reduciendo significativamente o eliminando por completo la aparición de errores de sintaxis.
    \item[\textbf{H3.}] La introducción de reflexión sobre errores y una mínima retroalimentación humana o automática permite al agente corregir patrones de falla recurrentes, contribuyendo al aumento de la solubilidad y la correctitud del \textit{PDDL} generado.
    \item[\textbf{H4.}] La incorporación de \textit{RAG} para la selección de ejemplos relevantes y la extracción de \textit{insights} a partir de soluciones previas (tanto correctas como erróneas), representa una vía prometedora para mejorar la capacidad de los agentes basados en \textit{LLMs} para modelar tareas de planificación, al permitirles adaptarse a la semántica de nuevas tareas y fortalecer su conocimiento sobre el dominio específico y la modelación de problemas.
\end{itemize}

\section*{Objetivo General}

Diseñar, implementar y evaluar agentes basados en \textit{LLMs} con técnicas propuestas para mejorar la correctitud sintáctica y semántica de la generación de códigos \textit{PDDL} en modelación de tareas de planificación, y realizar un análisis comparativo de los agentes implementados para determinar los factores que influyen positivamente en métricas como validez sintáctica, solubilidad y correctitud.

\section*{Objetivos Específicos}

\begin{enumerate}
	\item Realizar un estudio del estado del arte de agentes basados en \textit{LLMs} para modelación de problemas de planificación.

	\item Presentar un marco teórico-conceptual para establecer las definiciones fundamentales relacionados con la planificación automática, y las técnicas y recursos a utilizar en la propuesta de solución.

	\item Diseñar un agente basado en \textit{LLM} y variantes del mismo con técnicas propuestas para mejorar la correctitud sintáctica y semántica de la generación de códigos \textit{PDDL} en modelación de tareas de planificación, así como sus fases de entrenamiento, evaluación y análisis comparativo de los agentes propuestos y \textit{baselines} extraídos de los antecedentes descritos en la literatura. 

	\item Implementar los \textit{baselines}, el agente diseñado y sus variantes, para el posterior análisis de cómo afectan las distintas técnicas e ideas al rendimiento según métricas de validez sintáctica, solubilidad y correctitud. Además, implementar los \textit{pipelines} de generación de los subconjuntos de problemas para entrenamiento y evaluación de los agentes, así como los algoritmos que describen estos propios procesos.

	\item Evaluar las distintas variantes del agente en un \textit{benchmark} que permita analizar el rendimiento de agentes modeladores de problemas de planificación, según las métricas propuestas.

	\item Realizar un estudio estadístico y de ablación de los resultados de la evaluación, para identificar concretamente las posibles influencias que tienen las técnicas y métodos usados en las métricas analizadas.
	
\end{enumerate}

\section*{Propuesta de solución}

La presente investigación propone el desarrollo de agentes modeladores de problemas de planificación basados en \textit{LLMs}, cuya función principal sea la generación automática de archivos de problema \textit{PDDL} a partir de descripciones en lenguaje natural. El \textit{PDDL} generado se utiliza como entrada a un sistema planificador clásico (\textit{Fast Downward}) para generar un plan eficiente que resuelve el problema. Este agente opera en modalidad \textit{Open-Loop}\footnote{Un agente \textit{Open-Loop} genera un plan completo y estático antes de ejecutar cualquier acción, asumiendo un entorno determinista y sin incorporar retroalimentación durante la ejecución. Este enfoque contrasta con los sistemas \textit{Closed-Loop}, que ajustan el plan dinámicamente ante fallos o cambios en el entorno \parencite{wei2025plangenllms}.}, asumiendo un entorno determinista y sin retroalimentación del entorno, y es evaluado bajo el marco riguroso del \textit{benchmark Planetarium}, el cual permite medir automáticamente la validez sintáctica, solubilidad y correctitud semántica de los modelos generados. La entrada de los agentes es de base la descripción del dominio del problema, el archivo \textit{PDDL} del dominio, y la descripción en lenguaje natural del problema.

Para asegurar la validez sintáctica del código \textit{PDDL} generado por el agente modelador, se integra \textit{GCD} utilizando como \textit{baseline} una gramática \textit{GBNF} (\textit{Georgi Gerganov's Machine Learning (GGML) Backus--Naur form (BNF)}) \parencite{ggml2023gbnf}, derivada de la sintaxis general del subconjunto \textit{STRIPS} y \textit{:typing} de \textit{PDDL}. Se propone también el uso de gramáticas generadas automática y específicamente para el dominio y el problema a partir de una fase previa de extracción de objetos tipados, para limitar la generación de predicados a estos objetos, con aridad y tipado de argumentos correctos. Esta técnica se aplica tanto a la generación final del archivo \textit{PDDL} como a la fase intermedia de extracción de objetos.

Con inspiración en el enfoque experiencial del trabajo de \textit{ExpeL} bajo el paradigma \textit{LLM-as-Planner}, se propone su adaptación al paradigma \textit{LLM-as-Modeler}. Durante una fase de entrenamiento sobre un subconjunto estratificado del \textit{dataset Planetarium}, el agente recopila un conjunto de soluciones correctas e incorrectas. A partir de estas, se realiza una extracción sistemática de \textit{insights} (conocimiento condensado), orientada a mejorar el conocimiento general de modelación de problemas de planificación, así como a capturar conocimiento específico por dominio (por ejemplo, sobre el uso de predicados, limitaciones o reglas del dominio, o sus patrones típicos). Esta fase es reforzada en su mayoría con mecanismos de refinamiento mediante \textit{In-Context Reinforcement Learning}, y reflexión sobre fallos con \textit{feedback} (retroalimentación) construido automáticamente o por intervención humana mínima. Estos conocimientos se integran en el comportamiento del agente a través de \textit{In-Context Learning}.

Para mejorar la fidelidad semántica y la coherencia de las salidas, se emplea \textit{Few-Shot Prompting} enriquecido con \textit{RAG}, utilizando \textit{embeddings} de lenguaje natural de las descripciones textuales, para seleccionar ejemplos previos relevantes del \textit{corpus} de soluciones correctas construido durante la fase de entrenamiento. Un conjunto de \textit{insights} evoluciona mediante la actualización automática, por un \textit{LLM}, de los pesos y descripciones de los \textit{insights} mediante operaciones bien definidas. Esto permite una adaptación progresiva del agente basada en su experiencia acumulada durante el entrenamiento, con mínima intervención experta.

Para evaluar el impacto de cada componente del agente propuesto, se lleva a cabo un estudio comparativo incremental (en cuanto a las variantes evaluadas) sobre el \textit{dataset Planetarium}. Se diseñan distintas variantes del agente, activando o desactivando módulos específicos (como \textit{GCD}, Razonamiento estructurado o Extracción de objetos). Además se implementan \textit{baselines} contra los que comparar las variantes propuestas, como los agentes principales del trabajo de \textit{LLM+P} \parencite{liu2023llm+}: \textbf{LLM-as-P\textsuperscript{-}} (agente planificador \textit{Zero-shot}), \textbf{LLM-as-P\textsuperscript{+}} (agente planificador \textit{One-shot} con ejemplo fijo), \textbf{LLM+P\textsuperscript{-}} (agente modelador \textit{Zero-shot}) y \textbf{LLM+P\textsuperscript{+}} (agente modelador \textit{One-shot} con ejemplo fijo). Se miden los resultados de todos los agentes en subconjuntos estratificados del \textit{dataset}. Esto permite analizar la contribución relativa de cada técnica a la mejora de las métricas clave, así como la evolución de la calidad de las salidas del agente conforme se integran mecanismos más sofisticados de comprensión, generación y adaptación.

\section*{Estructura de la tesis}

La presente tesis se estructura en capítulos organizados de forma progresiva para guiar al lector desde el contexto del problema y los fundamentos conceptuales, hasta el diseño, implementación, evaluación y análisis de la solución propuesta:

\begin{itemize}
    \item \textbf{Introducción} \\
    Se presenta el contexto histórico-social donde se desarrolla la investigación, los antecedentes del problema, la problemática, la motivación y justificación, el diseño teórico, las hipótesis, los objetivos, la propuesta de solución y la estructura del trabajo.

    \item \textbf{Capítulo 1: Estado del Arte y Marco Teórico-Conceptual} \\
    Se realiza una revisión crítica de trabajos previos relevantes, incluyendo estudios sobre generación automática de \textit{PDDL} con \textit{LLMs}, agentes planificadores, agentes modeladores, enfoques recientes, etc. Se identifican las limitaciones existentes y se posiciona la contribución de esta tesis dentro del campo. Se abordan los conceptos fundamentales relacionados con la planificación automática, el lenguaje \textit{PDDL}, los modelos de lenguaje de gran escala (\textit{LLMs}), las técnicas de generación estructurada como \textit{GCD}, y los enfoques de razonamiento, aprendizaje experiencial, autorreflexión, \textit{In-Context Learning} reforzado con \textit{RAG}, etc. También se describe el \textit{benchmark Planetarium} y su sistema de evaluación.
    
    \item \textbf{Capítulo 2: Propuesta de Solución} \\
    Se describe el diseño del agente planificador propuesto, sus distintas fases (razonamiento, extracción de objetos, generación de \textit{PDDL}) y el uso de \textit{GCD} en diversas etapas. Se detalla el procedimiento de entrenamiento en acumulación de experiencias y extracción de \textit{insights}, el diseño de los \textit{prompts} y las gramáticas.
    
    \item \textbf{Capítulo 3: Implementación de la propuesta} \\
    Se explican las herramientas utilizadas, la arquitectura del sistema, y las decisiones y detalles de implementación.
    
    \item \textbf{Capítulo 4: Evaluación} \\
    Se presentan los experimentos realizados sobre el \textit{benchmark Planetarium}, comparando variantes del agente y evaluando su rendimiento según validez sintáctica, solubilidad y correctitud. Se analiza la influencia de cada componente de la mejora propuesta sobre estas métricas. Se justifican los experimentos propuestos respecto al análisis de cumplimiento de las hipótesis, en el contexto con limitaciones a las que las evaluaciones están sujetas.
    
    \item \textbf{Conclusiones} \\
    Se sintetizan los resultados obtenidos, se evalúa el cumplimiento de los objetivos y la validez de las hipótesis bajo las limitaciones observadas.
    
   \item \textbf{Recomendaciones y Trabajo Futuro} \\
    Se proponen múltiples líneas de trabajo futuras para mejorar y extender la propuesta, basadas en sus limitaciones e ideas de alto potencial no contempladas en esta investigación.

    \item \textbf{Bibliografía} \\
    Se presenta toda la bibliografía consultada para la realización de esta tesis, así como las referencias bibliográficas a literatura citada en este documento.
\end{itemize}