@article{li2024lasp,
  title={LASP: Surveying the State-of-the-Art in Large Language Model-Assisted AI Planning},
  author={Li, Haoming and Chen, Zhaoliang and Zhang, Jonathan and Liu, Fei},
  journal={arXiv preprint arXiv:2409.01806},
  year={2024}
}

@article{huang2402understanding,
  title={Understanding the planning of LLM agents: a survey (2024)},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={URL https://arxiv. org/abs/2402.02716}
}

@article{wei2025plangenllms,
  title={PlanGenLLMs: A Modern Survey of LLM Planning Capabilities},
  author={Wei, Hui and Zhang, Zihao and He, Shenghua and Xia, Tian and Pan, Shijia and Liu, Fei},
  journal={arXiv preprint arXiv:2502.11221},
  year={2025}
}

@article{tantakoun2025llms,
  title={LLMs as Planning Modelers: A Survey for Leveraging Large Language Models to Construct Automated Planning Models},
  author={Tantakoun, Marcus and Zhu, Xiaodan and Muise, Christian},
  journal={arXiv preprint arXiv:2503.18971},
  year={2025}
}

@article{aghzal2025survey,
  title={A survey on large language models for automated planning},
  author={Aghzal, Mohamed and Plaku, Erion and Stein, Gregory J and Yao, Ziyu},
  journal={arXiv preprint arXiv:2502.12435},
  year={2025}
}

@article{zuo2024planetarium,
  title={Planetarium: A rigorous benchmark for translating text to structured planning languages},
  author={Zuo, Max and Velez, Francisco Piedrahita and Li, Xiaochen and Littman, Michael L and Bach, Stephen H},
  journal={arXiv preprint arXiv:2407.03321},
  year={2024}
}

@article{liu2023llm+,
  title={Llm+ p: Empowering large language models with optimal planning proficiency},
  author={Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  journal={arXiv preprint arXiv:2304.11477},
  year={2023}
}

@article{dagan2023dynamic,
  title={Dynamic planning with a llm},
  author={Dagan, Gautier and Keller, Frank and Lascarides, Alex},
  journal={arXiv preprint arXiv:2308.06391},
  year={2023}
}

@article{wong2023learning,
  title={Learning adaptive planning representations with natural language guidance},
  author={Wong, Lionel and Mao, Jiayuan and Sharma, Pratyusha and Siegel, Zachary S and Feng, Jiahai and Korneev, Noa and Tenenbaum, Joshua B and Andreas, Jacob},
  journal={arXiv preprint arXiv:2312.08566},
  year={2023}
}

@inproceedings{agarwal2024tic,
  title={TIC: Translate-Infer-Compile for accurate “text to plan” using LLMs and Logical Representations},
  author={Agarwal, Sudhir and Sreepathy, Anu},
  booktitle={International Conference on Neural-Symbolic Learning and Reasoning},
  pages={222--244},
  year={2024},
  organization={Springer}
}

@article{xie2023translating,
  title={Translating natural language to planning goals with large-language models},
  author={Xie, Yaqi and Yu, Chen and Zhu, Tongyao and Bai, Jinbin and Gong, Ze and Soh, Harold},
  journal={arXiv preprint arXiv:2302.05128},
  year={2023}
}

@inproceedings{lee2024planning,
  title={Planning AI Assistant for Emergency Decision-Making (PlanAID): Framing Planning Problems and Assessing Plans with Large Language Models},
  author={Lee, Jacqueline and Cantu, Michelle and Korb, Joel and Meth, Eva and Griffith, John D and Korman, Joanna and Yuen, Anna and Schwartz, Peter and Gertner, Abigail S},
  booktitle={AAAI 2025 Workshop LM4Plan},
  year={2024}
}

@article{shinn2023reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={8634--8652},
  year={2023}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46534--46594},
  year={2023}
}

@inproceedings{zhao2024expel,
  title={Expel: Llm agents are experiential learners},
  author={Zhao, Andrew and Huang, Daniel and Xu, Quentin and Lin, Matthieu and Liu, Yong-Jin and Huang, Gao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={19632--19642},
  year={2024}
}

@article{sun2023adaplanner,
  title={Adaplanner: Adaptive planning from feedback with language models},
  author={Sun, Haotian and Zhuang, Yuchen and Kong, Lingkai and Dai, Bo and Zhang, Chao},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={58202--58245},
  year={2023}
}

@article{geng2023grammar,
  title={Grammar-constrained decoding for structured NLP tasks without finetuning},
  author={Geng, Saibo and Josifoski, Martin and Peyrard, Maxime and West, Robert},
  journal={arXiv preprint arXiv:2305.13971},
  year={2023}
}

@article{roy2024flap,
  title={FLAP: Flow-adhering planning with constrained decoding in LLMs},
  author={Roy, Shamik and Sengupta, Sailik and Bonadiman, Daniele and Mansour, Saab and Gupta, Arshit},
  journal={arXiv preprint arXiv:2403.05766},
  year={2024}
}

@article{wang2023grammar,
  title={Grammar prompting for domain-specific language generation with large language models},
  author={Wang, Bailin and Wang, Zi and Wang, Xuezhi and Cao, Yuan and A Saurous, Rif and Kim, Yoon},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={65030--65055},
  year={2023}
}

@article{loula2025syntactic,
  title={Syntactic and semantic control of large language models via sequential monte carlo},
  author={Loula, Jo{\~a}o and LeBrun, Benjamin and Du, Li and Lipkin, Ben and Pasti, Clemente and Grand, Gabriel and Liu, Tianyu and Emara, Yahya and Freedman, Marjorie and Eisner, Jason and others},
  journal={arXiv preprint arXiv:2504.13139},
  year={2025}
}

@article{gao2023retrieval,
  title={Retrieval-augmented generation for large language models: A survey},
  author={Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yixin and Sun, Jiawei and Wang, Haofen and Wang, Haofen},
  journal={arXiv preprint arXiv:2312.10997},
  volume={2},
  pages={1},
  year={2023}
}

@inproceedings{silver2022pddl,
  title={PDDL planning with pretrained large language models},
  author={Silver, Tom and Hariprasad, Varun and Shuttleworth, Reece S and Kumar, Nishanth and Lozano-P{\'e}rez, Tom{\'a}s and Kaelbling, Leslie Pack},
  booktitle={NeurIPS 2022 foundation models for decision making workshop},
  year={2022}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}

@article{aeronautiques1998pddl,
  title={Pddl| the planning domain definition language},
  author={Aeronautiques, Constructions and Howe, Adele and Knoblock, Craig and McDermott, ISI Drew and Ram, Ashwin and Veloso, Manuela and Weld, Daniel and Sri, David Wilkins and Barrett, Anthony and Christianson, Dave and others},
  journal={Technical Report, Tech. Rep.},
  year={1998}
}

@article{kovacs2011bnf,
  title={BNF definition of PDDL 3.1},
  author={Kovacs, Daniel L},
  journal={Unpublished manuscript from the IPC-2011 website},
  volume={15},
  year={2011}
}

@article{helmert2006fast,
  title={The fast downward planning system},
  author={Helmert, Malte},
  journal={Journal of Artificial Intelligence Research},
  volume={26},
  pages={191--246},
  year={2006}
}

@article{zeng2023agenttuning,
  title={Agenttuning: Enabling generalized agent abilities for llms},
  author={Zeng, Aohan and Liu, Mingdao and Lu, Rui and Wang, Bowen and Liu, Xiao and Dong, Yuxiao and Tang, Jie},
  journal={arXiv preprint arXiv:2310.12823},
  year={2023}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{fikes1971strips,
  title={STRIPS: A new approach to the application of theorem proving to problem solving},
  author={Fikes, Richard E and Nilsson, Nils J},
  journal={Artificial intelligence},
  volume={2},
  number={3-4},
  pages={189--208},
  year={1971},
  publisher={Elsevier}
}

@book{ghallab2004automated,
  title={Automated Planning: theory and practice},
  author={Ghallab, Malik and Nau, Dana and Traverso, Paolo},
  year={2004},
  publisher={Elsevier}
}

@article{marrella2019automated,
  title={Automated planning for business process management},
  author={Marrella, Andrea},
  journal={Journal on data semantics},
  volume={8},
  number={2},
  pages={79--98},
  year={2019},
  publisher={Springer}
}

@article{karpas2020automated,
  title={Automated planning for robotics},
  author={Karpas, Erez and Magazzeni, Daniele},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={3},
  number={1},
  pages={417--439},
  year={2020},
  publisher={Annual Reviews}
}

@inproceedings{richter2011lama,
  title={LAMA 2008 and 2011},
  author={Richter, Silvia and Westphal, Matthias and Helmert, Malte},
  booktitle={International Planning Competition},
  pages={117--124},
  year={2011},
  organization={ICAPS Freiburg, Germany}
}

@inproceedings{kambhampati2024position,
  title={Position: LLMs can’t plan, but can help planning in LLM-modulo frameworks},
  author={Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Verma, Mudit and Stechly, Kaya and Bhambri, Siddhant and Saldyt, Lucas Paul and Murthy, Anil B},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@book{lifschitz2019answer,
  title={Answer set programming},
  author={Lifschitz, Vladimir},
  volume={3},
  year={2019},
  publisher={Springer Cham}
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@article{wang2023learning,
  title={Learning to retrieve in-context examples for large language models},
  author={Wang, Liang and Yang, Nan and Wei, Furu},
  journal={arXiv preprint arXiv:2307.07164},
  year={2023}
}

@article{xiong2024converging,
  title={Converging paradigms: The synergy of symbolic and connectionist ai in llm-empowered autonomous agents},
  author={Xiong, Haoyi and Wang, Zhiyuan and Li, Xuhong and Bian, Jiang and Xie, Zeke and Mumtaz, Shahid and Al-Dulaimi, Anwer and Barnes, Laura E},
  journal={arXiv preprint arXiv:2407.08516},
  year={2024}
}

@article{zhuang2020comprehensive,
  title={A comprehensive survey on transfer learning},
  author={Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  journal={Proceedings of the IEEE},
  volume={109},
  number={1},
  pages={43--76},
  year={2020},
  publisher={Ieee}
}

@article{park2025survey,
  title={A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency},
  author={Park, Sihyeong and Jeon, Sungryeol and Lee, Chaelyn and Jeon, Seokhun and Kim, Byung-Soo and Lee, Jemin},
  journal={arXiv preprint arXiv:2505.01658},
  year={2025}
}

@article{geng2025generating,
  title={Generating Structured Outputs from Language Models: Benchmark and Studies},
  author={Geng, Saibo and Cooper, Hudson and Moskal, Micha{\l} and Jenkins, Samuel and Berman, Julian and Ranchin, Nathan and West, Robert and Horvitz, Eric and Nori, Harsha},
  journal={arXiv preprint arXiv:2501.10868},
  year={2025}
}

@misc{ggml2023gbnf,
  author       = {ggml-org},
  title        = {GBNF: Format for defining formal grammars to constrain model outputs in llama.cpp},
  year         = {2023},
  howpublished = {\url{https://github.com/ggml-org/llama.cpp/blob/master/grammars/README.md}},
  note         = {Accedido el 15 de mayo de 2025}
}

@inproceedings{howey2004val,
  title={VAL: Automatic plan validation, continuous effects and mixed initiative planning using PDDL},
  author={Howey, Richard and Long, Derek and Fox, Maria},
  booktitle={16th IEEE International Conference on Tools with Artificial Intelligence},
  pages={294--301},
  year={2004},
  organization={IEEE}
}

@misc{fireworks2025deepseekv3,
  author       = {FireworksAI},
  title        = {DeepSeek V3 Model},
  year         = {2025},
  howpublished = {\url{https://fireworks.ai/models/fireworks/deepseek-v3}},
  note         = {Accedido el 12 de junio de 2025}
}

@misc{fireworks2025llama3,
  author       = {FireworksAI},
  title        = {Llama 3.1 8B Instruct Model},
  year         = {2025},
  howpublished = {\url{https://fireworks.ai/models/fireworks/llama-v3p1-8b-instruct}},
  note         = {Accedido el 12 de junio de 2025}
}

@misc{fireworks2025llama4scout,
  author       = {FireworksAI},
  title        = {Llama 4 Scout Instruct (Basic) Model},
  year         = {2025},
  howpublished = {\url{https://fireworks.ai/models/fireworks/llama4-scout-instruct-basic}},
  note         = {Accedido el 12 de junio de 2025}
}

@misc{fireworks2025llama4maverick,
  author       = {FireworksAI},
  title        = {Llama 4 Maverick Instruct (Basic) Model},
  year         = {2025},
  howpublished = {\url{https://fireworks.ai/models/fireworks/llama4-maverick-instruct-basic}},
  note         = {Accedido el 12 de junio de 2025}
}

@article{sun2023reinforcement,
  title={Reinforcement learning in the era of llms: What is essential? what is needed? an rl perspective on rlhf, prompting, and beyond},
  author={Sun, Hao},
  journal={arXiv preprint arXiv:2310.06147},
  year={2023}
}

@article{pednault1987formulating,
  title={Formulating multiagent, dynamic-world problems in the classical planning framework},
  author={Pednault, Edwin},
  journal={Reasoning about actions and plans},
  pages={47--82},
  year={1987}
}

@article{aeronautiques1998pddl,
  title={Pddl| the planning domain definition language},
  author={Aeronautiques, Constructions and Howe, Adele and Knoblock, Craig and McDermott, ISI Drew and Ram, Ashwin and Veloso, Manuela and Weld, Daniel and Sri, David Wilkins and Barrett, Anthony and Christianson, Dave and others},
  journal={Technical Report, Tech. Rep.},
  year={1998}
}

@article{coles2012survey,
  title={A survey of the seventh international planning competition},
  author={Coles, Amanda and Coles, Andrew and Olaya, Angel Garc{\'\i}a and Jim{\'e}nez, Sergio and L{\'o}pez, Carlos Linares and Sanner, Scott and Yoon, Sungwook},
  journal={Ai Magazine},
  volume={33},
  number={1},
  pages={83--88},
  year={2012}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@misc{taori2023stanford,
  title={Stanford alpaca: An instruction-following llama model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year={2023},
  publisher={Stanford, CA, USA}
}

@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{aghzal2025survey,
  title={A survey on large language models for automated planning},
  author={Aghzal, Mohamed and Plaku, Erion and Stein, Gregory J and Yao, Ziyu},
  journal={arXiv preprint arXiv:2502.12435},
  year={2025}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{zhou2022least,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}

@article{wang2023plan,
  title={Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models},
  author={Wang, Lei and Xu, Wanyu and Lan, Yihuai and Hu, Zhiqiang and Lan, Yunshi and Lee, Roy Ka-Wei and Lim, Ee-Peng},
  journal={arXiv preprint arXiv:2305.04091},
  year={2023}
}

@inproceedings{stechly2024chain,
  title={Chain of thoughtlessness? an analysis of cot in planning},
  author={Stechly, Kaya and Valmeekam, Karthik and Kambhampati, Subbarao},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{li2024long,
  title={Long-context llms struggle with long in-context learning},
  author={Li, Tianle and Zhang, Ge and Do, Quy Duc and Yue, Xiang and Chen, Wenhu},
  journal={arXiv preprint arXiv:2404.02060},
  year={2024}
}

@inproceedings{yao2023react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@article{sun2023adaplanner,
  title={Adaplanner: Adaptive planning from feedback with language models},
  author={Sun, Haotian and Zhuang, Yuchen and Kong, Lingkai and Dai, Bo and Zhang, Chao},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={58202--58245},
  year={2023}
}

@article{shinn2023reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={8634--8652},
  year={2023}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46534--46594},
  year={2023}
}

@article{kim2023language,
  title={Language models can solve computer tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={39648--39677},
  year={2023}
}

@article{verma2024brittle,
  title={On the brittle foundations of react prompting for agentic large language models},
  author={Verma, Mudit and Bhambri, Siddhant and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2405.13966},
  year={2024}
}

@article{huang2023large,
  title={Large language models cannot self-correct reasoning yet},
  author={Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.01798},
  year={2023}
}

@article{stechly2024self,
  title={On the self-verification limitations of large language models on reasoning and planning tasks},
  author={Stechly, Kaya and Valmeekam, Karthik and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2402.08115},
  year={2024}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={11809--11822},
  year={2023}
}

@article{hao2023reasoning,
  title={Reasoning with language model is planning with world model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.14992},
  year={2023}
}

@article{chen2024tree,
  title={When is tree search useful for llm planning? it depends on the discriminator},
  author={Chen, Ziru and White, Michael and Mooney, Raymond and Payani, Ali and Su, Yu and Sun, Huan},
  journal={arXiv preprint arXiv:2402.10890},
  year={2024}
}

@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}

@article{bohnet2024exploring,
  title={Exploring and Benchmarking the Planning Capabilities of Large Language Models},
  author={Bohnet, Bernd and Nova, Azade and Parisi, Aaron T and Swersky, Kevin and Goshvadi, Katayoon and Dai, Hanjun and Schuurmans, Dale and Fiedel, Noah and Sedghi, Hanie},
  journal={arXiv preprint arXiv:2406.13094},
  year={2024}
}

@article{aghzal2023can,
  title={Can large language models be good path planners? a benchmark and investigation on spatial-temporal reasoning},
  author={Aghzal, Mohamed and Plaku, Erion and Yao, Ziyu},
  journal={arXiv preprint arXiv:2310.03249},
  year={2023}
}

@article{li2024unlocking,
  title={Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning},
  author={Li, Wenjun and Chen, Changyu and Varakantham, Pradeep},
  journal={arXiv preprint arXiv:2406.10479},
  year={2024}
}

@inproceedings{fine2024leveraging,
  title={Leveraging LLMs for Generating Document-Informed Hierarchical Planning Models: A Proposal},
  author={Fine-Morris, Morgan and Hsiao, Vincent and Smith, Leslie N and Hiatt, Laura M and Roberts, Mak},
  booktitle={AAAI 2025 Workshop LM4Plan},
  year={2024}
}

@article{zhang2024pddlego,
  title={Pddlego: Iterative planning in textual environments},
  author={Zhang, Li and Jansen, Peter and Zhang, Tianyi and Clark, Peter and Callison-Burch, Chris and Tandon, Niket},
  journal={arXiv preprint arXiv:2405.19793},
  year={2024}
}

@inproceedings{shirai2024vision,
  title={Vision-language interpreter for robot task planning},
  author={Shirai, Keisuke and Beltran-Hernandez, Cristian C and Hamaya, Masashi and Hashimoto, Atsushi and Tanaka, Shohei and Kawaharazuka, Kento and Tanaka, Kazutoshi and Ushiku, Yoshitaka and Mori, Shinsuke},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2051--2058},
  year={2024},
  organization={IEEE}
}

@inproceedings{lyu2023faithful,
  title={Faithful chain-of-thought reasoning},
  author={Lyu, Qing and Havaldar, Shreya and Stein, Adam and Zhang, Li and Rao, Delip and Wong, Eric and Apidianaki, Marianna and Callison-Burch, Chris},
  booktitle={The 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (IJCNLP-AACL 2023)},
  year={2023}
}

@article{collins2022structured,
  title={Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks},
  author={Collins, Katherine M and Wong, Catherine and Feng, Jiahai and Wei, Megan and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:2205.05718},
  year={2022}
}

@article{singh2024anticipate,
  title={Anticipate \& Collab: Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration},
  author={Singh, Shivam and Swaminathan, Karthik and Arora, Raghav and Singh, Ramandeep and Datta, Ahana and Das, Dipanjan and Banerjee, Snehasis and Sridharan, Mohan and Krishna, Madhava},
  journal={arXiv preprint arXiv:2404.03587},
  year={2024}
}

@inproceedings{izquierdo2024plancollabnl,
  title={Plancollabnl: Leveraging large language models for adaptive plan generation in human-robot collaboration},
  author={Izquierdo-Badiola, Silvia and Canal, Gerard and Rizzo, Carlos and Aleny{\`a}, Guillem},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={17344--17350},
  year={2024},
  organization={IEEE}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM computing surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{petroni2019language,
  title={Language models as knowledge bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  journal={arXiv preprint arXiv:1909.01066},
  year={2019}
}

@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}

@article{li2022survey,
  title={A survey on retrieval-augmented text generation},
  author={Li, Huayang and Su, Yixuan and Cai, Deng and Wang, Yan and Liu, Lemao},
  journal={arXiv preprint arXiv:2202.01110},
  year={2022}
}

@article{wang2023learning,
  title={Learning to retrieve in-context examples for large language models},
  author={Wang, Liang and Yang, Nan and Wei, Furu},
  journal={arXiv preprint arXiv:2307.07164},
  year={2023}
}

@article{rubin2021learning,
  title={Learning to retrieve prompts for in-context learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  journal={arXiv preprint arXiv:2112.08633},
  year={2021}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International conference on machine learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@article{liu2023reflect,
  title={Reflect: Summarizing robot experiences for failure explanation and correction},
  author={Liu, Zeyi and Bahety, Arpit and Song, Shuran},
  journal={arXiv preprint arXiv:2306.15724},
  year={2023}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}

@article{maas2023infinity,
  title={To infinity and beyond: Show-1 and showrunner agents in multi-agent simulations},
  author={Maas, Carey and Wheeler, Saatchi and Billington, Shamash and others},
  journal={To infinity and beyond: Show-1 and showrunner agents in multi-agent simulations},
  year={2023}
}

@article{qian2023communicative,
  title={Communicative agents for software development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  volume={6},
  number={3},
  year={2023}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@article{yue2023offline,
  title={Offline prioritized experience replay},
  author={Yue, Yang and Kang, Bingyi and Ma, Xiao and Huang, Gao and Song, Shiji and Yan, Shuicheng},
  journal={arXiv preprint arXiv:2306.05412},
  volume={6},
  year={2023}
}

@inproceedings{backus1959syntax,
  title={The syntax and the semantics of the proposed international algebraic language of the Zurich ACM-GAMM Conference},
  author={Backus, John W},
  booktitle={ICIP Proceedings},
  pages={125--132},
  year={1959}
}

@article{backus1963revised,
  title={Revised report on the algorithmic language Algol 60},
  author={Backus, John W and Bauer, Friedrich L and Green, Julien and Katz, Charles and McCarthy, John and Perlis, Alan J and Rutishauser, Heinz and Samelson, Klaus and Vauquois, Bernard and Wegstein, Joseph Henry and others},
  journal={Communications of the ACM},
  volume={6},
  number={1},
  pages={1--17},
  year={1963},
  publisher={ACM New York, NY, USA}
}

@article{knuth1964backus,
  title={Backus normal form vs. backus naur form},
  author={Knuth, Donald E},
  journal={Communications of the ACM},
  volume={7},
  number={12},
  pages={735--736},
  year={1964},
  publisher={ACM New York, NY, USA}
}

@book{peter2021modern,
  title={A Modern Approach},
  author={Peter, Norvig and Intelligence, Russell Stuart Artificial},
  year={2021},
  publisher={Pearson Education, USA}
}

@online{weinmeister2024zero,
  author    = {Reinier Weinmeister},
  title     = {Is a Zero Temperature Deterministic?},
  year      = {2024},
  date      = {2024-03-14},
  url       = {https://medium.com/google-cloud/is-a-zero-temperature-deterministic-c4a7faef4d20},
  note      = {Blog en \emph{Medium}, accedido el 12 de junio de 2025}
}

@online{pamelatoman2023nondeterminism,
  author    = {Pamela Toman},
  title     = {Why LLM Outputs Aren’t Always Reproducible: Sources of Non-Determinism},
  year      = {2023},
  date      = {2023-08-25},
  url       = {https://www.pamelatoman.net/blog/2023/08/nondeterminism-in-llms/},
  note      = {Blog personal, accedido el 12 de junio de 2025}
}

@book{efron1994introduction,
  title={An introduction to the bootstrap},
  author={Efron, Bradley and Tibshirani, Robert J},
  year={1994},
  publisher={Chapman and Hall/CRC}
}

@article{smirnov2024generating,
  title={Generating consistent PDDL domains with Large Language Models},
  author={Smirnov, Pavel and Joublin, Frank and Ceravola, Antonello and Gienger, Michael},
  journal={arXiv preprint arXiv:2404.07751},
  year={2024}
}

@article{reimers2019sentence,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@misc{sentence_transformers_allmpnet,
  author = {HuggingFace},
  title = {sentence-transformers/all-mpnet-base-v2},
  year = {2025},
  url = {https://huggingface.co/sentence-transformers/all-mpnet-base-v2},
  note = {Accedido el 12 de junio de 2025}
}

@article{singhal2001modern,
  title={Modern information retrieval: A brief overview},
  author={Singhal, Amit and others},
  journal={IEEE Data Eng. Bull.},
  volume={24},
  number={4},
  pages={35--43},
  year={2001}
}

@article{turing1936computable,
  title={On computable numbers, with an application to the Entscheidungsproblem},
  author={Turing, Alan Mathison and others},
  journal={J. of Math},
  volume={58},
  number={345-363},
  pages={5},
  year={1936},
  publisher={Wiley Online Library}
}

@article{church1936unsolvable,
  title={An unsolvable problem of elementary number theory},
  author={Church, Alonzo},
  journal={American journal of mathematics},
  volume={58},
  number={2},
  pages={345--363},
  year={1936},
  publisher={JSTOR}
}
