\babel@toc {spanish}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Imagen extraída de \blx@tocontentsinit {0}\textcite {geng2023grammar}: \textit {Grammar-Constrained Decoding (GCD)} aplicado a la tarea de \textit {closed information extraction}, donde el objetivo es extraer una lista $y$ de tripletes sujeto–relación–objeto del texto de entrada $x$. Los sujetos y objetos están restringidos a ser entidades de \textit {Wikidata}, y las relaciones a ser una relación de \textit {Wikidata}. Durante la decodificación, solo se consideran continuaciones de \textit {tokens} válidas que cumplen con la gramática. Por simplicidad, se omiten los símbolos de marcador especiales \texttt {[s]}, \texttt {[r]} y \texttt {[o]} en el esquema del proceso de generación.}}{17}{figure.caption.16}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Dominios de problemas de planificación del \textit {benchmark Planetarium}, de izquierda a derecha: \textit {Blocksworld}, \textit {Gripper} y \textit {Floor-Tile}}}{20}{figure.caption.17}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces Imagen extraída del \textit {paper} de \textit {Planetarium} \blx@tocontentsinit {0}\parencite {zuo2024planetarium}: ejemplo de cómo un único objetivo de planificación puede corresponder a múltiples estados objetivos \textit {PDDL} correctos. Todos los objetivos \textit {PDDL} en la fila superior representan la meta mostrada correctamente. La fila inferior ilustra objetivos \textit {PDDL} con diferentes tipos de errores, mostrando instancias que son solubles (un planificador puede generar un plan, pero para un problema de planificación diferente), sintácticamente válidos (la sintaxis \textit {PDDL} es correcta pero no producirá ningún plan con un planificador) e inválidos (contiene errores de sintaxis).}}{21}{figure.caption.18}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Flujo de evaluación de los agentes modeladores propuestos.}}{24}{figure.caption.19}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Flujo de evaluación de los agentes modeladores experienciales propuestos.}}{37}{figure.caption.24}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Imagen adaptada del \textit {paper} de \textit {ExpeL} \blx@tocontentsinit {0}\parencite {zhao2024expel}. Izquierda: se opera en tres etapas: (1) Recolección de experiencias de éxito y fracaso en un \textit {pool}. (2) Extracción/abstracción de conocimiento entre tareas a partir de estas experiencias. (3) Aplicación de los conocimientos adquiridos y recuerdo de éxitos pasados en tareas de evaluación. Derecha: (A) Ilustra el proceso de recolección de experiencias a través del agente reflexionador, permitiendo reintentos de la tarea después de la autorreflexión sobre los fracasos. (B) Ilustra el paso de extracción de conocimiento. Cuando se le presentan pares de éxito/fracaso o una lista de $L$ éxitos, el agente modifica dinámicamente una lista existente de conocimientos $\hat {\iota }$ utilizando las operaciones \texttt {ADD}, \texttt {AGREE}, \texttt {REMOVE} y \texttt {EDIT}.}}{39}{figure.caption.25}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Porcentaje de planes válidos por agente en tareas con descripción completamente explícita.}}{56}{figure.caption.28}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Métricas calculadas por agente}}{58}{figure.caption.31}%
