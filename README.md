# PLAN-GRAIL ğŸ§ ğŸ”§
**<u>P</u>lanning with <u>L</u>LM-based <u>A</u>gents via <u>N</u>euro-symbolic modeling with <u>G</u>rammar-Constrained decoding, <u>R</u>easoning, and <u>A</u>ctive <u>I</u>n-context <u>L</u>earning**

[![Status](https://img.shields.io/badge/status-Research%20Prototype-yellow)]()
[![Python](https://img.shields.io/badge/python-3.12%2B-blue)]()
[![MadeWithML](https://img.shields.io/badge/Made%20with-ğŸ¤–%20LLMs-red)]()

PLAN-GRAIL is a modular and extensible modeling agent based on the **LLM-as-Modeler** paradigm. Its main objective is to automatically generate syntactically valid, solvable, and semantically correct PDDL (Planning Domain Definition Language) problem files from natural language descriptions, enabling classical planners to solve real-world planning tasks with minimal human intervention.

This work builds upon and extends the results of prior efforts such as [LLM+P](https://arxiv.org/abs/2304.11477), identifying their key limitations in generalization, syntax validation, and semantic coherence. The proposed solution introduces a set of enhancements and new techniques to address these challenges, including:

- âœ… **Grammar-Constrained Decoding (GCD)** using both handcrafted and problem-specific grammars derived from BNF specifications of PDDL, ensuring syntactic validity.
- ğŸ§± **Structured Multi-phase Reasoning**, including explicit object extraction and intermediate representations.
- ğŸ” **Reflection with Automatic Feedback**, using failures and minimal human intervention to refine outputs.
- ğŸ“š **Experiential Learning**, inspired by the ExpeL approach under the LLM-as-Planner paradigm, where the agent accumulates experience, extracts symbolic insights, and evolves its reasoning through iterative training and refinement.
- ğŸ¯ **Few-Shot Prompting + RAG**, leveraging semantic retrieval of previously successful examples and learned insights to improve semantic fidelity and generalization.

The agent operates in an **Open-Loop** setting: it assumes a deterministic environment and does not incorporate execution feedback during planning. All models are evaluated using the **Planetarium** benchmark, which enables automatic verification of syntax, solvability, and semantic correctness. Comparative experiments with LLM+P baselines and agent variants demonstrate the cumulative impact of each component and the effectiveness of PLAN-GRAILâ€™s guided modeling pipeline.

---

## ğŸ“ Abstract

Symbolic modeling of planning tasks remains one of the main bottlenecks for the practical adoption of classical planners in real-world contexts. While the *LLM-as-Planner* paradigm has recently gained attention, it faces serious limitations in verifiability and optimality. As an alternative, this thesis adopts the *LLM-as-Modeler* approach, in which agents based on *Large Language Models (LLMs)* automatically generate *PDDL (Planning Domain Definition Language)* models of planning problems from their natural language descriptions. A modular and extensible modeling agent is proposed, designed to improve the parseability, solvability, and semantic correctness of the generated models. The architecture combines multiple complementary techniques: structured multi-phase reasoning, *Grammar-Constrained Decoding (GCD)*, automatic feedback and failure-driven reflection, experiential learning through solution and *insight* extraction and refinement, and *Few-Shot Prompting* enriched with *Retrieval-Augmented Generation (RAG)*.

Empirical evaluation was conducted on stratified subsets of the *Planetarium* benchmark, comparing relevant *LLM+P* baselines and several variants of the proposed agent. Results show significant improvements across all key metrics, including the complete elimination of syntactic errors via *GCD* with specialized grammars, and an increase of up to **24.3â€¯%** in semantic correctness over the best reproduced *baseline*, closing **56.7â€¯%** of its performance gap. The combined inclusion of structured reasoning, object extraction, and *GCD* enabled a performance of **100â€¯%** parseability, **87.1â€¯%** solvability, and **81.4â€¯%** correctness. By incorporating mechanisms for reflection and automatic feedback, residual errors were corrected, raising solvability to **98.57â€¯%** and correctness to **84.29â€¯%**. Finally, the synergistic combination of retries with reflection, retrieval of prior examples, and manually constructed *insights* further increased these rates to **100â€¯%** and **87.14â€¯%**, respectively.

This work contributes a functional architecture, a reproducible evaluation framework, and empirical evidence that properly guided and trained *LLMs* can serve as effective modeling agents. The proposed approach opens new perspectives for the design of hybrid neuro-symbolic systems in automated planning, with reduced reliance on expert human intervention.

---

## ğŸ“Œ Context

Many real-world problems â€” from robotics to logistics â€” can be expressed as planning tasks. While classical planners are powerful, their adoption is hindered by the burden of symbolic modeling.

Recent LLM-based approaches often skip modeling altogether, directly generating plans. However, this sacrifices verifiability, optimality, and generality. PLAN-GRAIL stands on the LLM-as-Modeler paradigm: generate **PDDL models** from natural language, and let symbolic planners do the planning.

The proposed framework is trained and evaluated over the [Planetarium Benchmark](https://arxiv.org/abs/2407.03321).

![Context: Planning Domains](docs/Graphics/domains.png)
---

## ğŸš€ Research Contributions

- âœ… A modular **LLM-based modeling agent** guided by grammar, structured reasoning, and experiential learning.
- ğŸ§  Integration of **Grammar-Constrained Decoding (GCD)** with domain-specific grammars.
- ğŸ” Experiential training inspired by [ExpeL](https://arxiv.org/abs/2308.10144v3), with feedback-driven reflection and insight extraction.
- ğŸ” Use of **Retrieval-Augmented Generation (RAG)** and **Few-Shot Prompting (FSP)** for better contextualization and transfer.
- ğŸ§ª A reproducible **evaluation framework** over stratified subsets of the [Planetarium Benchmark](https://arxiv.org/abs/2407.03321).

---

## ğŸ§ª Proposal & Architecture

PLAN-GRAIL is composed of several complementary modules:

- **Structured Multi-Phase Modeling**: object extraction, goal analysis, PDDL assembly.
- **GCD with GBNF Grammars**: enforce syntactic validity at generation time.
- **Reflection & Feedback**: correct failures through guided retries and corrections.
- **Experiential Learning**: derive insights from both failed and successful generations.
- **RAG + FSP**: reuse relevant prior examples via embedding similarity.

### Evaluation Pipeline

![Evaluation Flow](docs/Graphics/evaluation.png)

### Experience-Driven Refinement

![System Design](docs/Graphics/training.png)

### Experiential Agent Evaluation

![Experience Evaluation](docs/Graphics/exp_evaluation.png)

---

## Comparison with LLM-based direct-planning agents 

![Valid Plans by Agent](docs/Graphics/valid_plans_by_agent.png)

## ğŸ“Š Evaluation Results

We evaluated PLAN-GRAIL and its ablations across 70 planning tasks from the Planetarium benchmark, focusing on three metrics:

- âœ… **Syntactic Validity**
- ğŸ”„ **Solvability**
- ğŸ§  **Semantic Correctness**

![Metrics Grid](docs/Graphics/metrics_grid.png)

The integration of structured reasoning, object extraction, and *GCD* allowed for **100 %** parseability, with solvability and correctness initially measured at **87.1 %** and **81.4 %**, respectively. 

The incorporation of reflection mechanisms and automatic feedback led to a significant improvement in these metrics, raising solvability to **98.57 %** and correctness to **84.29 %**. Further performance gains were achieved through a combination of reflection-based retries, retrieval of analogous examples, and manually derived *insights*, culminating in **100 %** solvability and **87.14 %** correctness.

---

## ğŸ“ Repository Structure

```bash
ğŸ“¦ Thesis
 â”£ ğŸ“‚ docs/                       # LaTeX source files to generate the written thesis PDF
 â”£ ğŸ“‚ src/                        # Project root (source code)
 â”ƒ â”£ ğŸ“‚ agents/                   # Implementation of modeler and planner agents
 â”ƒ â”ƒ â”£ ğŸ“„ modeler_agents.py         # Modeler agents with proposed enhancements
 â”ƒ â”ƒ â”£ ğŸ“„ orig_llm_plus_p_agents.py # Original LLM+P baseline modeler agents
 â”ƒ â”ƒ â”£ ğŸ“„ planner_agents.py         # LLM-as-Planner agents used as baselines
 â”ƒ â”ƒ â”— ğŸ“„ reflection_agent.py       # Error-reflecting agent module
 â”ƒ â”£ ğŸ“‚ classical_planner/        # Wrapper for external classical planners
 â”ƒ â”ƒ â”— ğŸ“„ planner.py                # Interface to Fast Downward
 â”ƒ â”£ ğŸ“‚ client/                   # Interface to LLM APIs
 â”ƒ â”ƒ â”£ ğŸ“‚ queries/                  # Logs of LLM queries (as JSON)
 â”ƒ â”ƒ â”£ ğŸ“„ client.py                # Fireworks AI client for LLM querying
 â”ƒ â”ƒ â”— ğŸ“„ token_consumption.json   # Token usage logs per request
 â”ƒ â”£ ğŸ“‚ dataset/                 # Dataset handling and documentation
 â”ƒ â”ƒ â”£ ğŸ“‚ subsets/                 # Stratified evaluation/training subsets
 â”ƒ â”ƒ â”£ ğŸ“„ dataset.py              # Dataset loading and slicing logic
 â”ƒ â”ƒ â”£ ğŸ“„ dataset-v4.db           # SQLite database of Planetarium
 â”ƒ â”ƒ â”— ğŸ“„ report.md               # Technical dataset report
 â”ƒ â”£ ğŸ“‚ domains/                 # Planning domain resources
 â”ƒ â”ƒ â”£ ğŸ“‚ blocksworld/             # Blocksworld domain resources
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ domain.pddl             # PDDL domain file
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ domain_description.txt  # Textual domain description
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ actions_description.txt # Action descriptions
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ fsp_ex_nl.txt           # Natural language description for FSP example
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ fsp_ex_objects.json     # Typed objects from FSP example
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ fsp_ex_pddl.pddl        # Generated PDDL file for FSP example
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ fsp_ex_plan.pddl        # Classical plan for FSP example
 â”ƒ â”ƒ â”ƒ â”£ ğŸ“„ fsp_ex_reasoning.txt    # Structured reasoning steps
 â”ƒ â”ƒ â”ƒ â”— ğŸ“„ planner_output_syntax.txt # Expected planner output format
 â”ƒ â”ƒ â”£ ğŸ“‚ floor-tile/              # Analogous files for Floor-Tile
 â”ƒ â”ƒ â”£ ğŸ“‚ gripper/                 # Analogous files for Gripper
 â”ƒ â”ƒ â”— ğŸ“„ utils.py                 # Utilities for domain handling
 â”ƒ â”£ ğŸ“‚ exp/                     # Experiential learning module
 â”ƒ â”ƒ â”£ ğŸ“‚ exps/                    # Experience pool accumulated during training
 â”ƒ â”ƒ â”£ ğŸ“‚ operations/              # Insight extraction operation logs
 â”ƒ â”ƒ â”£ ğŸ“„ experience_pool.py       # Management of experience pool
 â”ƒ â”ƒ â”£ ğŸ“„ insights.json            # Extracted and human-built insights
 â”ƒ â”ƒ â”£ ğŸ“„ insights_extraction.py   # Insight extraction logic
 â”ƒ â”ƒ â”£ ğŸ“„ insights_extraction_progress.json # Insight extraction progress tracking
 â”ƒ â”ƒ â”£ ğŸ“„ training.py              # Experiential agent training logic
 â”ƒ â”ƒ â”— ğŸ“„ training_progress.json   # Training progress tracking
 â”ƒ â”£ ğŸ“‚ grammar/                # GCD grammar construction
 â”ƒ â”ƒ â”£ ğŸ“„ grammar.py               # Grammar building methods
 â”ƒ â”ƒ â”£ ğŸ“„ kovacs-pddl-3.1-2011.pdf # Official PDDL 3.1 BNF specification
 â”ƒ â”ƒ â”— ğŸ“„ pddl_bnf.py              # PDDL BNF grammar as code
 â”ƒ â”£ ğŸ“‚ rag/                    # Retrieval-Augmented Generation module
 â”ƒ â”ƒ â”£ ğŸ“„ api_embedder.py          # Embeddings via HuggingFace API
 â”ƒ â”ƒ â”£ ğŸ“„ embeddings_with_ids_test5.npz  # Precomputed test embeddings
 â”ƒ â”ƒ â”£ ğŸ“„ embeddings_with_ids_train5.npz # Precomputed train embeddings
 â”ƒ â”ƒ â”£ ğŸ“„ local_embedder.py        # Local embedding via sentence-transformers
 â”ƒ â”ƒ â”— ğŸ“„ retriever.py             # RAG retriever class
 â”ƒ â”£ ğŸ“‚ results/                # Evaluation results
 â”ƒ â”£ ğŸ“‚ utils/                  # Shared utility functions
 â”ƒ â”ƒ â”£ ğŸ“„ evaluation_utils.py      # Evaluation methods for generated models
 â”ƒ â”ƒ â”£ ğŸ“„ io_utils.py              # File I/O utilities
 â”ƒ â”ƒ â”£ ğŸ“„ pddl_utils.py            # PDDL file handling functions
 â”ƒ â”ƒ â”£ ğŸ“„ planning_utils.py        # Classical planner integration helpers
 â”ƒ â”ƒ â”£ ğŸ“„ result_utils.py          # Results formatting and processing
 â”ƒ â”ƒ â”— ğŸ“„ tokens_utils.py          # Token usage analysis
 â”ƒ â”£ ğŸ“‚ validator/              # Plan validator module
 â”ƒ â”ƒ â”— ğŸ“„ validator.py             # Integration with VAL
 â”ƒ â”£ ğŸ“‚ visualizer/            # Results visualization
 â”ƒ â”ƒ â”— ğŸ“„ visualizer.py            # Plotting and metrics diagrams
 â”ƒ â”£ ğŸ“„ check_planetarium_generation.py # Dataset validation script
 â”ƒ â”£ ğŸ“„ config.py                 # Global config and hyperparameters
 â”ƒ â”£ ğŸ“„ evaluations_progress.json        # Logs for basic agent evaluations
 â”ƒ â”£ ğŸ“„ exp_evaluation_progress.json     # Logs for experiential agent evaluations
 â”ƒ â”— ğŸ“„ main.py                  # Project entry point
```

---

## ğŸ“š Citation

If you use PLAN-GRAIL in your research, please cite it as follows:

```bibtex
@thesis{gonzalez2025plangrail,
  title     = {PLAN-GRAIL: Planning with LLM-based Agents via Neuro-symbolic modeling with Grammar-Constrained Decoding, Reasoning and Active In-Context Learning},
  author    = {Ariel GonzÃ¡lez GÃ³mez},
  year      = {2025},
  type      = {Bachelor's Thesis},
  school    = {Universidad de La Habana},
  url       = {https://github.com/arielgg46/Thesis},
  note      = {Available at: \url{https://github.com/arielgg46/Thesis}}
}
```
